{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-CnBMpKxasb"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install packages\n",
        "!pip install google-generativeai gradio plotly pandas sqlalchemy requests -q\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import google.generativeai as genai\n",
        "import gradio as gr\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Setup Gemini API (UPDATED)\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Method 1: Store API key in Colab Secrets (Recommended)\n",
        "# Go to üîë icon in left sidebar ‚Üí Add secret ‚Üí Name: GEMINI_API_KEY\n",
        "try:\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "except:\n",
        "    # Method 2: Direct input (less secure)\n",
        "    GEMINI_API_KEY = input(\"Enter your Gemini API key: \")\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# ‚úÖ FIXED: Use updated model name\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')  # Updated model name\n",
        "\n",
        "print(\"‚úÖ Gemini API configured successfully!\")\n",
        "\n",
        "# Test the model\n",
        "try:\n",
        "    test_response = model.generate_content(\"Hello, this is a test.\")\n",
        "    print(\"‚úÖ Model test successful!\")\n",
        "    print(f\"Test response: {test_response.text[:50]}...\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Model test failed: {e}\")\n",
        "    print(\"\\nüîß Trying alternative model names...\")\n",
        "\n",
        "    # Try other available models\n",
        "    alternative_models = [\n",
        "        'gemini-1.5-pro',\n",
        "        'gemini-1.0-pro',\n",
        "        'models/gemini-1.5-flash',\n",
        "        'models/gemini-1.5-pro'\n",
        "    ]\n",
        "\n",
        "    for alt_model in alternative_models:\n",
        "        try:\n",
        "            model = genai.GenerativeModel(alt_model)\n",
        "            test_response = model.generate_content(\"Hello, this is a test.\")\n",
        "            print(f\"‚úÖ Success with model: {alt_model}\")\n",
        "            break\n",
        "        except:\n",
        "            print(f\"‚ùå Failed with model: {alt_model}\")\n",
        "    else:\n",
        "        print(\"‚ùå All models failed. Please check your API key and try again.\")"
      ],
      "metadata": {
        "id": "brpR2Lgtxp9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Upload your three datasets\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "print(\"üìÅ Upload your THREE CSV files:\")\n",
        "print(\"1. Product-Level Eligibility Table\")\n",
        "print(\"2. Product-Level Ad Sales and Metrics\")\n",
        "print(\"3. Product-Level Total Sales and Metrics\")\n",
        "print(\"\\nClick 'Choose Files' and select ALL THREE files at once (Ctrl+click or Cmd+click)\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Verify we have 3 files\n",
        "print(f\"\\n‚úÖ Total files uploaded: {len(uploaded)}\")\n",
        "\n",
        "# List uploaded files with preview\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\nüìÅ File: {filename}\")\n",
        "    print(f\"   Size: {len(uploaded[filename])} bytes\")\n",
        "\n",
        "    # Show first few rows of each file\n",
        "    try:\n",
        "        df = pd.read_csv(filename)\n",
        "        print(f\"   Rows: {len(df)}, Columns: {len(df.columns)}\")\n",
        "        print(f\"   Column names: {list(df.columns)}\")\n",
        "        print(f\"   First few rows:\")\n",
        "        print(df.head(2).to_string())\n",
        "    except Exception as e:\n",
        "        print(f\"   Error reading file: {e}\")\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Check if we have all required files\n",
        "expected_files = 3\n",
        "if len(uploaded) == expected_files:\n",
        "    print(f\"‚úÖ Perfect! All {expected_files} files uploaded successfully!\")\n",
        "elif len(uploaded) < expected_files:\n",
        "    print(f\"‚ö†Ô∏è  Warning: Expected {expected_files} files, but only {len(uploaded)} uploaded.\")\n",
        "    print(\"   You can run this cell again to upload more files.\")\n",
        "else:\n",
        "    print(f\"‚ÑπÔ∏è  Info: You uploaded {len(uploaded)} files (more than expected {expected_files}).\")\n",
        "    print(\"   That's fine - we'll use all of them!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "L4HOvGUNxxtA",
        "outputId": "09ce3739-a830-4105-f24c-7cc2db0ae201",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Upload your THREE CSV files:\n",
            "1. Product-Level Eligibility Table\n",
            "2. Product-Level Ad Sales and Metrics\n",
            "3. Product-Level Total Sales and Metrics\n",
            "\n",
            "Click 'Choose Files' and select ALL THREE files at once (Ctrl+click or Cmd+click)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1ad1f4f0-79c9-4bd1-9eee-4982b3b0fbbb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1ad1f4f0-79c9-4bd1-9eee-4982b3b0fbbb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Product-Level Ad Sales and Metrics (mapped) - Product-Level Ad Sales and Metrics (mapped).csv to Product-Level Ad Sales and Metrics (mapped) - Product-Level Ad Sales and Metrics (mapped) (1).csv\n",
            "Saving Product-Level Eligibility Table (mapped) - Product-Level Eligibility Table (mapped).csv to Product-Level Eligibility Table (mapped) - Product-Level Eligibility Table (mapped) (1).csv\n",
            "Saving Product-Level Total Sales and Metrics (mapped) - Product-Level Total Sales and Metrics (mapped).csv to Product-Level Total Sales and Metrics (mapped) - Product-Level Total Sales and Metrics (mapped) (1).csv\n",
            "\n",
            "‚úÖ Total files uploaded: 3\n",
            "\n",
            "üìÅ File: Product-Level Ad Sales and Metrics (mapped) - Product-Level Ad Sales and Metrics (mapped) (1).csv\n",
            "   Size: 102585 bytes\n",
            "   Rows: 3696, Columns: 7\n",
            "   Column names: ['date', 'item_id', 'ad_sales', 'impressions', 'ad_spend', 'clicks', 'units_sold']\n",
            "   First few rows:\n",
            "         date  item_id  ad_sales  impressions  ad_spend  clicks  units_sold\n",
            "0  2025-06-01        0    332.96         1963     16.87       8           3\n",
            "1  2025-06-01        1      0.00         1764     20.39      11           0\n",
            "--------------------------------------------------\n",
            "\n",
            "üìÅ File: Product-Level Eligibility Table (mapped) - Product-Level Eligibility Table (mapped) (1).csv\n",
            "   Size: 263031 bytes\n",
            "   Rows: 4381, Columns: 4\n",
            "   Column names: ['eligibility_datetime_utc', 'item_id', 'eligibility', 'message']\n",
            "   First few rows:\n",
            "  eligibility_datetime_utc  item_id  eligibility                                                                                                                                                                                                                   message\n",
            "0       2025-06-04 8:50:07       29        False  This product's cost to Amazon does not allow us to meet customers‚Äô pricing expectations. Consider reducing the cost. It may take a few weeks for your product to become eligible to advertise after you reduce the cost.\n",
            "1       2025-06-04 8:50:07      270         True                                                                                                                                                                                                                       NaN\n",
            "--------------------------------------------------\n",
            "\n",
            "üìÅ File: Product-Level Total Sales and Metrics (mapped) - Product-Level Total Sales and Metrics (mapped) (1).csv\n",
            "   Size: 15899 bytes\n",
            "   Rows: 702, Columns: 4\n",
            "   Column names: ['date', 'item_id', 'total_sales', 'total_units_ordered']\n",
            "   First few rows:\n",
            "         date  item_id  total_sales  total_units_ordered\n",
            "0  2025-06-01        0       309.99                    1\n",
            "1  2025-06-01        3       338.00                    2\n",
            "--------------------------------------------------\n",
            "‚úÖ Perfect! All 3 files uploaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Create database (FIXED VERSION)\n",
        "def setup_database():\n",
        "    # Create database connection\n",
        "    conn = sqlite3.connect('ecommerce_data.db')\n",
        "\n",
        "    # Load uploaded CSV files\n",
        "    csv_files = [f for f in uploaded.keys() if f.endswith('.csv')]\n",
        "\n",
        "    tables_created = []\n",
        "    for csv_file in csv_files:\n",
        "        # Read CSV\n",
        "        df = pd.read_csv(csv_file)\n",
        "\n",
        "        # Clean table name more aggressively\n",
        "        table_name = csv_file.lower()\n",
        "\n",
        "        # Remove file extension\n",
        "        table_name = table_name.replace('.csv', '')\n",
        "\n",
        "        # Clean up the name - keep only letters, numbers, underscores\n",
        "        import re\n",
        "        table_name = re.sub(r'[^a-z0-9_]', '_', table_name)\n",
        "\n",
        "        # Remove multiple underscores and leading/trailing underscores\n",
        "        table_name = re.sub(r'_+', '_', table_name).strip('_')\n",
        "\n",
        "        # Shorten long names\n",
        "        if len(table_name) > 30:\n",
        "            if 'ad_sales' in table_name:\n",
        "                table_name = 'ad_sales_metrics'\n",
        "            elif 'eligibility' in table_name:\n",
        "                table_name = 'product_eligibility'\n",
        "            elif 'total_sales' in table_name:\n",
        "                table_name = 'total_sales_metrics'\n",
        "            else:\n",
        "                table_name = table_name[:30]\n",
        "\n",
        "        # Ensure it doesn't start with a number\n",
        "        if table_name[0].isdigit():\n",
        "            table_name = 't_' + table_name\n",
        "\n",
        "        # Create table\n",
        "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "        tables_created.append((table_name, list(df.columns)))\n",
        "\n",
        "        print(f\"‚úÖ Created table: {table_name}\")\n",
        "        print(f\"   Columns: {list(df.columns)}\")\n",
        "        print(f\"   Rows: {len(df)}\")\n",
        "        print(f\"   Sample data:\")\n",
        "        print(f\"   {df.head(2).to_string()}\")\n",
        "        print()\n",
        "\n",
        "    conn.close()\n",
        "    return tables_created\n",
        "\n",
        "# Run the fixed setup\n",
        "tables_info = setup_database()\n",
        "\n",
        "# Show final table summary\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìä DATABASE SUMMARY:\")\n",
        "print(\"=\"*50)\n",
        "for table_name, columns in tables_info:\n",
        "    print(f\"Table: {table_name}\")\n",
        "    print(f\"Columns: {', '.join(columns)}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCWya1Rnxzul",
        "outputId": "99f9ed1d-c104-43ae-fe1c-79bb512d86b0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Created table: ad_sales_metrics\n",
            "   Columns: ['date', 'item_id', 'ad_sales', 'impressions', 'ad_spend', 'clicks', 'units_sold']\n",
            "   Rows: 3696\n",
            "   Sample data:\n",
            "            date  item_id  ad_sales  impressions  ad_spend  clicks  units_sold\n",
            "0  2025-06-01        0    332.96         1963     16.87       8           3\n",
            "1  2025-06-01        1      0.00         1764     20.39      11           0\n",
            "\n",
            "‚úÖ Created table: product_eligibility\n",
            "   Columns: ['eligibility_datetime_utc', 'item_id', 'eligibility', 'message']\n",
            "   Rows: 4381\n",
            "   Sample data:\n",
            "     eligibility_datetime_utc  item_id  eligibility                                                                                                                                                                                                                   message\n",
            "0       2025-06-04 8:50:07       29        False  This product's cost to Amazon does not allow us to meet customers‚Äô pricing expectations. Consider reducing the cost. It may take a few weeks for your product to become eligible to advertise after you reduce the cost.\n",
            "1       2025-06-04 8:50:07      270         True                                                                                                                                                                                                                       NaN\n",
            "\n",
            "‚úÖ Created table: total_sales_metrics\n",
            "   Columns: ['date', 'item_id', 'total_sales', 'total_units_ordered']\n",
            "   Rows: 702\n",
            "   Sample data:\n",
            "            date  item_id  total_sales  total_units_ordered\n",
            "0  2025-06-01        0       309.99                    1\n",
            "1  2025-06-01        3       338.00                    2\n",
            "\n",
            "\n",
            "==================================================\n",
            "üìä DATABASE SUMMARY:\n",
            "==================================================\n",
            "Table: ad_sales_metrics\n",
            "Columns: date, item_id, ad_sales, impressions, ad_spend, clicks, units_sold\n",
            "\n",
            "Table: product_eligibility\n",
            "Columns: eligibility_datetime_utc, item_id, eligibility, message\n",
            "\n",
            "Table: total_sales_metrics\n",
            "Columns: date, item_id, total_sales, total_units_ordered\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick Verification Cell - Run this instead of the debug cell\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "def verify_clean_tables():\n",
        "    \"\"\"Verify that our clean tables are working properly\"\"\"\n",
        "    conn = sqlite3.connect('ecommerce_data.db')\n",
        "\n",
        "    # Test the clean tables we want to use\n",
        "    clean_tables = ['ad_sales_metrics', 'product_eligibility', 'total_sales_metrics']\n",
        "\n",
        "    print(\"üîç VERIFYING CLEAN TABLES:\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    working_tables = {}\n",
        "\n",
        "    for table_name in clean_tables:\n",
        "        try:\n",
        "            # Test basic query\n",
        "            query = f\"SELECT COUNT(*) as row_count FROM {table_name}\"\n",
        "            result = pd.read_sql_query(query, conn)\n",
        "            row_count = result.iloc[0]['row_count']\n",
        "\n",
        "            # Get column info\n",
        "            columns_query = f\"PRAGMA table_info({table_name})\"\n",
        "            columns_df = pd.read_sql_query(columns_query, conn)\n",
        "            columns = columns_df['name'].tolist()\n",
        "\n",
        "            # Get sample data\n",
        "            sample_query = f\"SELECT * FROM {table_name} LIMIT 3\"\n",
        "            sample_data = pd.read_sql_query(sample_query, conn)\n",
        "\n",
        "            print(f\"‚úÖ {table_name}:\")\n",
        "            print(f\"   Rows: {row_count}\")\n",
        "            print(f\"   Columns: {columns}\")\n",
        "            print(f\"   Sample data:\")\n",
        "            print(f\"   {sample_data.head(2).to_string()}\")\n",
        "            print()\n",
        "\n",
        "            working_tables[table_name] = {\n",
        "                'columns': columns,\n",
        "                'row_count': row_count\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error with {table_name}: {e}\")\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    # Clean up duplicate tables (optional)\n",
        "    if len(working_tables) == 3:\n",
        "        print(\"üßπ CLEANING UP DUPLICATE TABLES...\")\n",
        "        conn = sqlite3.connect('ecommerce_data.db')\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Drop the messy-named duplicate tables\n",
        "        messy_tables = [\n",
        "            'product_level_ad_sales_and_metrics_(mapped)___product_level_ad_sales_and_metrics_(mapped)',\n",
        "            'product_level_eligibility_table_(mapped)___product_level_eligibility_table_(mapped)',\n",
        "            'product_level_total_sales_and_metrics_(mapped)___product_level_total_sales_and_metrics_(mapped)'\n",
        "        ]\n",
        "\n",
        "        for messy_table in messy_tables:\n",
        "            try:\n",
        "                cursor.execute(f\"DROP TABLE IF EXISTS [{messy_table}]\")\n",
        "                print(f\"üóëÔ∏è Removed duplicate: {messy_table}\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    return working_tables\n",
        "\n",
        "# Run verification\n",
        "tables_status = verify_clean_tables()\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"üéØ SUMMARY:\")\n",
        "if len(tables_status) == 3:\n",
        "    print(\"‚úÖ All 3 tables are working perfectly!\")\n",
        "    print(\"‚úÖ Database is ready for the AI Agent!\")\n",
        "    print(\"\\nüöÄ NEXT STEP: Run Cell 5 (AI Agent initialization)\")\n",
        "\n",
        "    # Test the required questions will work\n",
        "    print(\"\\nüß™ CAPABILITY CHECK:\")\n",
        "    print(\"‚úÖ Total Sales: Can sum 'total_sales' column\")\n",
        "    print(\"‚úÖ RoAS: Can calculate 'ad_sales' √∑ 'ad_spend'\")\n",
        "    print(\"‚úÖ Highest CPC: Can find max 'ad_spend' √∑ 'clicks'\")\n",
        "else:\n",
        "    print(f\"‚ùå Only {len(tables_status)} tables working. Check your data upload.\")"
      ],
      "metadata": {
        "id": "90ZL674G5e7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: AI Agent Implementation (ROBUST VERSION)\n",
        "class EcommerceAIAgent:\n",
        "    def __init__(self, db_path='ecommerce_data.db'):\n",
        "        self.db_path = db_path\n",
        "        self.model = model  # Use the model that was successfully initialized\n",
        "        self.schema_info = self.get_schema_info()\n",
        "\n",
        "    def get_schema_info(self):\n",
        "        \"\"\"Get database schema information with robust error handling\"\"\"\n",
        "        try:\n",
        "            conn = sqlite3.connect(self.db_path)\n",
        "            cursor = conn.cursor()\n",
        "\n",
        "            # Get all tables\n",
        "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "            tables = cursor.fetchall()\n",
        "\n",
        "            if not tables:\n",
        "                print(\"‚ùå No tables found in database!\")\n",
        "                return {}\n",
        "\n",
        "            schema_info = {}\n",
        "            for table in tables:\n",
        "                table_name = table[0]\n",
        "                try:\n",
        "                    # Use square brackets to handle any special characters\n",
        "                    cursor.execute(f\"PRAGMA table_info([{table_name}]);\")\n",
        "                    columns = cursor.fetchall()\n",
        "                    schema_info[table_name] = {\n",
        "                        'columns': [col[1] for col in columns],\n",
        "                        'types': [(col[1], col[2]) for col in columns]\n",
        "                    }\n",
        "                    print(f\"‚úÖ Loaded schema for table: {table_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Error loading schema for {table_name}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            conn.close()\n",
        "            return schema_info\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Database connection error: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def generate_sql(self, question):\n",
        "        \"\"\"Convert natural language question to SQL\"\"\"\n",
        "        if not self.schema_info:\n",
        "            return \"Error: No database schema available\"\n",
        "\n",
        "        schema_text = self._format_schema_for_prompt()\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a SQL expert. Convert the following question to a SQL query.\n",
        "\n",
        "Database Schema:\n",
        "{schema_text}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Important Rules:\n",
        "1. Return ONLY the SQL query, no explanations or markdown\n",
        "2. Use exact table names and column names from the schema above\n",
        "3. For calculations like RoAS, use (revenue/ad_spend) formula\n",
        "4. For total sales, sum all revenue/sales columns\n",
        "5. Always use LIMIT 100 unless asked for more\n",
        "6. Use proper SQL syntax\n",
        "\n",
        "SQL Query:\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(\n",
        "                prompt,\n",
        "                generation_config=genai.GenerationConfig(\n",
        "                    temperature=0.1,\n",
        "                    max_output_tokens=300\n",
        "                )\n",
        "            )\n",
        "            sql_query = response.text.strip()\n",
        "\n",
        "            # Clean the SQL query\n",
        "            sql_query = re.sub(r'^```sql\\s*', '', sql_query)\n",
        "            sql_query = re.sub(r'^```\\s*', '', sql_query)\n",
        "            sql_query = re.sub(r'\\s*```$', '', sql_query)\n",
        "            sql_query = sql_query.strip()\n",
        "\n",
        "            return sql_query\n",
        "        except Exception as e:\n",
        "            print(f\"AI generation error: {e}\")\n",
        "            return self._generate_fallback_sql(question)\n",
        "\n",
        "    def _generate_fallback_sql(self, question):\n",
        "        \"\"\"Generate basic SQL queries when AI fails\"\"\"\n",
        "        question_lower = question.lower()\n",
        "        table_names = list(self.schema_info.keys())\n",
        "\n",
        "        if not table_names:\n",
        "            return \"Error: No tables available\"\n",
        "\n",
        "        # Get all columns from all tables\n",
        "        all_columns = []\n",
        "        for table_name, info in self.schema_info.items():\n",
        "            for col in info['columns']:\n",
        "                all_columns.append((table_name, col))\n",
        "\n",
        "        if \"total sales\" in question_lower:\n",
        "            # Look for sales/revenue columns\n",
        "            sales_cols = [(t, c) for t, c in all_columns\n",
        "                         if any(keyword in c.lower() for keyword in ['sales', 'revenue', 'amount'])]\n",
        "\n",
        "            if sales_cols:\n",
        "                table, col = sales_cols[0]\n",
        "                return f\"SELECT SUM([{col}]) as total_sales FROM [{table}];\"\n",
        "\n",
        "        elif \"roas\" in question_lower:\n",
        "            # Look for revenue and ad_spend columns\n",
        "            rev_cols = [(t, c) for t, c in all_columns if 'revenue' in c.lower()]\n",
        "            spend_cols = [(t, c) for t, c in all_columns if 'spend' in c.lower() or 'cost' in c.lower()]\n",
        "\n",
        "            if rev_cols and spend_cols:\n",
        "                table = rev_cols[0][0]  # Use first table found\n",
        "                return f\"SELECT *, ([{rev_cols[0][1]}]/[{spend_cols[0][1]}]) as roas FROM [{table}] WHERE [{spend_cols[0][1]}] > 0 LIMIT 10;\"\n",
        "\n",
        "        elif \"cpc\" in question_lower:\n",
        "            cpc_cols = [(t, c) for t, c in all_columns if 'cpc' in c.lower()]\n",
        "            if cpc_cols:\n",
        "                table, col = cpc_cols[0]\n",
        "                return f\"SELECT * FROM [{table}] ORDER BY [{col}] DESC LIMIT 10;\"\n",
        "\n",
        "        # Default: show first table\n",
        "        return f\"SELECT * FROM [{table_names[0]}] LIMIT 10;\"\n",
        "\n",
        "    def execute_query(self, sql_query):\n",
        "        \"\"\"Execute SQL query and return results\"\"\"\n",
        "        try:\n",
        "            conn = sqlite3.connect(self.db_path)\n",
        "            result = pd.read_sql_query(sql_query, conn)\n",
        "            conn.close()\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error executing query: {str(e)}\\nSQL: {sql_query}\"\n",
        "            print(error_msg)\n",
        "            return error_msg\n",
        "\n",
        "    def format_response(self, question, result, sql_query):\n",
        "        \"\"\"Format the response in natural language\"\"\"\n",
        "        if isinstance(result, str):  # Error case\n",
        "            return result\n",
        "\n",
        "        if len(result) == 0:\n",
        "            return \"No data found for your query.\"\n",
        "\n",
        "        # Simple formatting for reliable results\n",
        "        if len(result) == 1 and len(result.columns) == 1:\n",
        "            # Single value result\n",
        "            value = result.iloc[0, 0]\n",
        "            return f\"Answer: {value:,.2f}\" if isinstance(value, (int, float)) else f\"Answer: {value}\"\n",
        "\n",
        "        # Table result\n",
        "        result_preview = result.head(5).to_string()\n",
        "        return f\"Results for '{question}':\\n\\n{result_preview}\\n\\n(Showing first 5 rows of {len(result)} total rows)\"\n",
        "\n",
        "    def _format_schema_for_prompt(self):\n",
        "        \"\"\"Format schema information for the prompt\"\"\"\n",
        "        schema_text = \"\"\n",
        "        for table_name, info in self.schema_info.items():\n",
        "            schema_text += f\"\\nTable: {table_name}\\n\"\n",
        "            schema_text += f\"Columns: {', '.join(info['columns'])}\\n\"\n",
        "        return schema_text\n",
        "\n",
        "    def create_visualization(self, result, question):\n",
        "        \"\"\"Create simple visualization\"\"\"\n",
        "        if isinstance(result, str) or len(result) == 0:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            if len(result.columns) == 2 and len(result) <= 20 and result.iloc[:, 1].dtype in ['int64', 'float64']:\n",
        "                fig = px.bar(result, x=result.columns[0], y=result.columns[1],\n",
        "                           title=f\"Chart: {question}\")\n",
        "                return fig\n",
        "        except:\n",
        "            pass\n",
        "        return None\n",
        "\n",
        "    def process_question(self, question):\n",
        "        \"\"\"Main method to process a question\"\"\"\n",
        "        # Generate SQL\n",
        "        sql_query = self.generate_sql(question)\n",
        "\n",
        "        if sql_query.startswith(\"Error\"):\n",
        "            return {\n",
        "                'question': question,\n",
        "                'sql_query': sql_query,\n",
        "                'result': sql_query,\n",
        "                'chart': None\n",
        "            }\n",
        "\n",
        "        # Execute query\n",
        "        result = self.execute_query(sql_query)\n",
        "\n",
        "        # Format response\n",
        "        formatted_response = self.format_response(question, result, sql_query)\n",
        "\n",
        "        # Create visualization\n",
        "        chart = self.create_visualization(result, question)\n",
        "\n",
        "        return {\n",
        "            'question': question,\n",
        "            'sql_query': sql_query,\n",
        "            'result': formatted_response,\n",
        "            'data': result,\n",
        "            'chart': chart\n",
        "        }\n",
        "\n",
        "# Initialize agent with comprehensive error handling\n",
        "print(\"üöÄ Initializing AI Agent...\")\n",
        "\n",
        "try:\n",
        "    agent = EcommerceAIAgent()\n",
        "\n",
        "    if agent.schema_info:\n",
        "        print(\"‚úÖ AI Agent initialized successfully!\")\n",
        "        print(f\"üìä Available tables: {list(agent.schema_info.keys())}\")\n",
        "\n",
        "        for table_name, info in agent.schema_info.items():\n",
        "            print(f\"\\nüìã Table: {table_name}\")\n",
        "            print(f\"   Columns ({len(info['columns'])}): {', '.join(info['columns'][:5])}{'...' if len(info['columns']) > 5 else ''}\")\n",
        "\n",
        "        print(\"\\nüéØ Ready to answer questions!\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå No schema loaded. Database may be empty or corrupted.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing agent: {e}\")\n",
        "    print(\"\\nüîß Troubleshooting steps:\")\n",
        "    print(\"1. Run the debug cell above first\")\n",
        "    print(\"2. Make sure your database was created successfully\")\n",
        "    print(\"3. Check that your Excel files were uploaded properly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9ajumfCx2ld",
        "outputId": "fee86751-e1db-4714-c1e6-4463338338c9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Initializing AI Agent...\n",
            "‚úÖ Loaded schema for table: ad_sales_metrics\n",
            "‚úÖ Loaded schema for table: product_eligibility\n",
            "‚úÖ Loaded schema for table: total_sales_metrics\n",
            "‚úÖ AI Agent initialized successfully!\n",
            "üìä Available tables: ['ad_sales_metrics', 'product_eligibility', 'total_sales_metrics']\n",
            "\n",
            "üìã Table: ad_sales_metrics\n",
            "   Columns (7): date, item_id, ad_sales, impressions, ad_spend...\n",
            "\n",
            "üìã Table: product_eligibility\n",
            "   Columns (4): eligibility_datetime_utc, item_id, eligibility, message\n",
            "\n",
            "üìã Table: total_sales_metrics\n",
            "   Columns (4): date, item_id, total_sales, total_units_ordered\n",
            "\n",
            "üéØ Ready to answer questions!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Enhanced Conversational AI Agent with Chat Memory\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "class ConversationalEcommerceAgent:\n",
        "    def __init__(self, db_path='ecommerce_data.db'):\n",
        "        self.db_path = db_path\n",
        "        self.model = model  # Use existing Gemini model\n",
        "        self.schema_info = self.get_schema_info()\n",
        "        self.conversation_history = []\n",
        "        self.context_memory = {\n",
        "            'last_queries': [],\n",
        "            'user_preferences': {},\n",
        "            'frequently_asked': {}\n",
        "        }\n",
        "\n",
        "    def get_schema_info(self):\n",
        "        \"\"\"Get database schema with sample data for better context\"\"\"\n",
        "        try:\n",
        "            conn = sqlite3.connect(self.db_path)\n",
        "            cursor = conn.cursor()\n",
        "\n",
        "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "            tables = cursor.fetchall()\n",
        "\n",
        "            schema_info = {}\n",
        "            for table in tables:\n",
        "                table_name = table[0]\n",
        "                # Get column info\n",
        "                cursor.execute(f\"PRAGMA table_info([{table_name}]);\")\n",
        "                columns = cursor.fetchall()\n",
        "\n",
        "                # Get sample data for context\n",
        "                cursor.execute(f\"SELECT * FROM [{table_name}] LIMIT 3;\")\n",
        "                sample_data = cursor.fetchall()\n",
        "\n",
        "                # Get data ranges for numeric columns\n",
        "                numeric_columns = [col[1] for col in columns if col[2] in ['REAL', 'INTEGER']]\n",
        "                ranges = {}\n",
        "                for col in numeric_columns:\n",
        "                    try:\n",
        "                        cursor.execute(f\"SELECT MIN([{col}]), MAX([{col}]), AVG([{col}]) FROM [{table_name}] WHERE [{col}] IS NOT NULL;\")\n",
        "                        min_val, max_val, avg_val = cursor.fetchone()\n",
        "                        ranges[col] = {'min': min_val, 'max': max_val, 'avg': avg_val}\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                schema_info[table_name] = {\n",
        "                    'columns': [col[1] for col in columns],\n",
        "                    'types': [(col[1], col[2]) for col in columns],\n",
        "                    'sample_data': sample_data,\n",
        "                    'ranges': ranges,\n",
        "                    'row_count': self._get_row_count(cursor, table_name)\n",
        "                }\n",
        "\n",
        "            conn.close()\n",
        "            return schema_info\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading schema: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _get_row_count(self, cursor, table_name):\n",
        "        \"\"\"Get total row count for a table\"\"\"\n",
        "        try:\n",
        "            cursor.execute(f\"SELECT COUNT(*) FROM [{table_name}];\")\n",
        "            return cursor.fetchone()[0]\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def understand_intent(self, question):\n",
        "        \"\"\"Enhanced intent understanding with conversation context\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Check for conversation context\n",
        "        context_prompt = \"\"\n",
        "        if self.conversation_history:\n",
        "            recent_questions = [item['question'] for item in self.conversation_history[-3:]]\n",
        "            context_prompt = f\"\\nPrevious questions in this conversation: {recent_questions}\"\n",
        "\n",
        "        # Enhanced schema context\n",
        "        schema_context = self._create_rich_schema_context()\n",
        "\n",
        "        intent_prompt = f\"\"\"\n",
        "You are an AI assistant analyzing e-commerce data questions. Based on the conversation context and database schema, understand what the user wants.\n",
        "\n",
        "Database Context:\n",
        "{schema_context}\n",
        "{context_prompt}\n",
        "\n",
        "Current Question: \"{question}\"\n",
        "\n",
        "Analyze the intent and provide:\n",
        "1. Primary goal (what they want to know)\n",
        "2. Relevant tables to query\n",
        "3. Key metrics/columns needed\n",
        "4. Any filtering or grouping requirements\n",
        "5. Expected output format\n",
        "\n",
        "Respond in JSON format:\n",
        "{{\n",
        "    \"intent\": \"brief description\",\n",
        "    \"tables\": [\"table1\", \"table2\"],\n",
        "    \"metrics\": [\"column1\", \"column2\"],\n",
        "    \"filters\": \"any filtering needed\",\n",
        "    \"output_type\": \"single_value|table|chart|comparison\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(intent_prompt)\n",
        "            intent_text = response.text.strip()\n",
        "\n",
        "            # Extract JSON from response\n",
        "            import json\n",
        "            if '{' in intent_text and '}' in intent_text:\n",
        "                json_start = intent_text.find('{')\n",
        "                json_end = intent_text.rfind('}') + 1\n",
        "                intent_json = json.loads(intent_text[json_start:json_end])\n",
        "                return intent_json\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Fallback intent detection\n",
        "        return self._basic_intent_detection(question_lower)\n",
        "\n",
        "    def _basic_intent_detection(self, question_lower):\n",
        "        \"\"\"Fallback intent detection\"\"\"\n",
        "        if any(word in question_lower for word in ['total', 'sum', 'all']):\n",
        "            return {\n",
        "                \"intent\": \"Get total/sum of metrics\",\n",
        "                \"tables\": [\"total_sales_metrics\", \"ad_sales_metrics\"],\n",
        "                \"metrics\": [\"total_sales\", \"ad_sales\"],\n",
        "                \"filters\": \"\",\n",
        "                \"output_type\": \"single_value\"\n",
        "            }\n",
        "        elif any(word in question_lower for word in ['roas', 'return on ad spend']):\n",
        "            return {\n",
        "                \"intent\": \"Calculate Return on Ad Spend\",\n",
        "                \"tables\": [\"ad_sales_metrics\"],\n",
        "                \"metrics\": [\"ad_sales\", \"ad_spend\"],\n",
        "                \"filters\": \"ad_spend > 0\",\n",
        "                \"output_type\": \"table\"\n",
        "            }\n",
        "        elif any(word in question_lower for word in ['cpc', 'cost per click']):\n",
        "            return {\n",
        "                \"intent\": \"Calculate Cost Per Click\",\n",
        "                \"tables\": [\"ad_sales_metrics\"],\n",
        "                \"metrics\": [\"ad_spend\", \"clicks\"],\n",
        "                \"filters\": \"clicks > 0\",\n",
        "                \"output_type\": \"table\"\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"intent\": \"General data exploration\",\n",
        "                \"tables\": list(self.schema_info.keys()),\n",
        "                \"metrics\": [],\n",
        "                \"filters\": \"\",\n",
        "                \"output_type\": \"table\"\n",
        "            }\n",
        "\n",
        "    def _create_rich_schema_context(self):\n",
        "        \"\"\"Create detailed schema context for better AI understanding\"\"\"\n",
        "        context = \"DATABASE SCHEMA AND SAMPLE DATA:\\n\"\n",
        "\n",
        "        for table_name, info in self.schema_info.items():\n",
        "            context += f\"\\nTable: {table_name} ({info['row_count']} rows)\\n\"\n",
        "            context += f\"Columns: {', '.join(info['columns'])}\\n\"\n",
        "\n",
        "            if info['ranges']:\n",
        "                context += \"Data Ranges:\\n\"\n",
        "                for col, range_info in info['ranges'].items():\n",
        "                    context += f\"  {col}: {range_info['min']:.2f} to {range_info['max']:.2f} (avg: {range_info['avg']:.2f})\\n\"\n",
        "\n",
        "            if info['sample_data']:\n",
        "                context += f\"Sample Data: {info['sample_data'][0]}\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "    def generate_enhanced_sql(self, question, intent):\n",
        "        \"\"\"Generate SQL with enhanced context and conversation memory\"\"\"\n",
        "        schema_text = self._create_rich_schema_context()\n",
        "\n",
        "        # Add conversation context\n",
        "        conversation_context = \"\"\n",
        "        if self.conversation_history:\n",
        "            conversation_context = \"\\nPrevious successful queries:\\n\"\n",
        "            for item in self.conversation_history[-2:]:\n",
        "                if not item['sql_query'].startswith('Error'):\n",
        "                    conversation_context += f\"Q: {item['question']}\\nSQL: {item['sql_query']}\\n\\n\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are an expert SQL analyst for e-commerce data. Generate precise SQL queries.\n",
        "\n",
        "{schema_text}\n",
        "{conversation_context}\n",
        "\n",
        "User Intent Analysis:\n",
        "- Goal: {intent['intent']}\n",
        "- Relevant Tables: {intent['tables']}\n",
        "- Key Metrics: {intent['metrics']}\n",
        "- Expected Output: {intent['output_type']}\n",
        "\n",
        "Current Question: \"{question}\"\n",
        "\n",
        "IMPORTANT RULES:\n",
        "1. Use EXACT table and column names from schema above\n",
        "2. For calculations like RoAS: use (ad_sales/ad_spend) only where ad_spend > 0\n",
        "3. For CPC: use (ad_spend/clicks) only where clicks > 0\n",
        "4. Always include meaningful column aliases\n",
        "5. Use JOINs when combining data from multiple tables\n",
        "6. Add ORDER BY for meaningful sorting\n",
        "7. Use LIMIT appropriately (10-100 rows for tables, no limit for single values)\n",
        "\n",
        "Generate only the SQL query (no explanations):\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(\n",
        "                prompt,\n",
        "                generation_config=genai.GenerationConfig(\n",
        "                    temperature=0.1,\n",
        "                    max_output_tokens=500\n",
        "                )\n",
        "            )\n",
        "\n",
        "            sql_query = response.text.strip()\n",
        "            sql_query = re.sub(r'^```sql\\s*', '', sql_query, flags=re.IGNORECASE)\n",
        "            sql_query = re.sub(r'^```\\s*', '', sql_query)\n",
        "            sql_query = re.sub(r'\\s*```$', '', sql_query)\n",
        "            sql_query = sql_query.strip()\n",
        "\n",
        "            return sql_query\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"SQL generation error: {e}\")\n",
        "            return self._generate_smart_fallback(question, intent)\n",
        "\n",
        "    def _generate_smart_fallback(self, question, intent):\n",
        "        \"\"\"Smart fallback SQL generation\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        if intent['output_type'] == 'single_value':\n",
        "            if 'total' in question_lower and 'sales' in question_lower:\n",
        "                return \"SELECT SUM(total_sales) as total_sales FROM total_sales_metrics;\"\n",
        "\n",
        "        elif 'roas' in question_lower:\n",
        "            return \"\"\"\n",
        "            SELECT item_id,\n",
        "                   ad_sales,\n",
        "                   ad_spend,\n",
        "                   ROUND(ad_sales/ad_spend, 2) as roas\n",
        "            FROM ad_sales_metrics\n",
        "            WHERE ad_spend > 0\n",
        "            ORDER BY roas DESC\n",
        "            LIMIT 10;\n",
        "            \"\"\"\n",
        "\n",
        "        elif 'cpc' in question_lower:\n",
        "            return \"\"\"\n",
        "            SELECT item_id,\n",
        "                   ad_spend,\n",
        "                   clicks,\n",
        "                   ROUND(ad_spend/clicks, 2) as cpc\n",
        "            FROM ad_sales_metrics\n",
        "            WHERE clicks > 0\n",
        "            ORDER BY cpc DESC\n",
        "            LIMIT 10;\n",
        "            \"\"\"\n",
        "\n",
        "        # Default exploration\n",
        "        return \"SELECT * FROM ad_sales_metrics LIMIT 10;\"\n",
        "\n",
        "    def execute_query_with_retry(self, sql_query, max_retries=2):\n",
        "        \"\"\"Execute query with retry logic and error handling\"\"\"\n",
        "        for attempt in range(max_retries + 1):\n",
        "            try:\n",
        "                conn = sqlite3.connect(self.db_path)\n",
        "                result = pd.read_sql_query(sql_query, conn)\n",
        "                conn.close()\n",
        "                return result\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < max_retries:\n",
        "                    # Try to fix common SQL errors\n",
        "                    fixed_query = self._fix_common_sql_errors(sql_query, str(e))\n",
        "                    if fixed_query != sql_query:\n",
        "                        sql_query = fixed_query\n",
        "                        continue\n",
        "\n",
        "                return f\"Query execution failed: {str(e)}\"\n",
        "\n",
        "        return \"Query failed after retries\"\n",
        "\n",
        "    def _fix_common_sql_errors(self, sql_query, error_msg):\n",
        "        \"\"\"Fix common SQL errors automatically\"\"\"\n",
        "        if \"no such column\" in error_msg.lower():\n",
        "            # Try to fix column name issues\n",
        "            for table_name, info in self.schema_info.items():\n",
        "                for col in info['columns']:\n",
        "                    if col.lower() in sql_query.lower():\n",
        "                        sql_query = sql_query.replace(col, f\"[{col}]\")\n",
        "\n",
        "        if \"no such table\" in error_msg.lower():\n",
        "            # Try to fix table name issues\n",
        "            for table_name in self.schema_info.keys():\n",
        "                if table_name.lower() in sql_query.lower():\n",
        "                    sql_query = sql_query.replace(table_name, f\"[{table_name}]\")\n",
        "\n",
        "        return sql_query\n",
        "\n",
        "    def format_conversational_response(self, question, result, sql_query, intent):\n",
        "        \"\"\"Format response in a conversational way\"\"\"\n",
        "        if isinstance(result, str):  # Error case\n",
        "            return f\"I'm sorry, I encountered an issue: {result}\\n\\nLet me try a different approach. Could you rephrase your question?\"\n",
        "\n",
        "        if len(result) == 0:\n",
        "            return \"I didn't find any data matching your question. Could you try asking about something else?\"\n",
        "\n",
        "        # Format based on intent and result type\n",
        "        if intent['output_type'] == 'single_value' and len(result) == 1 and len(result.columns) == 1:\n",
        "            value = result.iloc[0, 0]\n",
        "            if isinstance(value, (int, float)):\n",
        "                if value > 1000000:\n",
        "                    formatted_value = f\"${value:,.0f}\"\n",
        "                elif value > 1000:\n",
        "                    formatted_value = f\"${value:,.2f}\"\n",
        "                else:\n",
        "                    formatted_value = f\"{value:.2f}\"\n",
        "            else:\n",
        "                formatted_value = str(value)\n",
        "\n",
        "            return f\"Based on your data, the answer is: **{formatted_value}**\\n\\nThis calculation was performed across {self._get_data_context(sql_query)} records in your database.\"\n",
        "\n",
        "        # Table results with conversational context\n",
        "        response = f\"Here's what I found for your question:\\n\\n\"\n",
        "\n",
        "        if len(result) > 10:\n",
        "            response += f\"**Top Results** (showing 10 of {len(result)} total):\\n\\n\"\n",
        "            display_result = result.head(10)\n",
        "        else:\n",
        "            response += f\"**All Results** ({len(result)} items):\\n\\n\"\n",
        "            display_result = result\n",
        "\n",
        "        response += display_result.to_string(index=False)\n",
        "        response += f\"\\n\\nüí° **Insights**: {self._generate_insights(result, question)}\"\n",
        "\n",
        "        return response\n",
        "\n",
        "    def _get_data_context(self, sql_query):\n",
        "        \"\"\"Extract data context from SQL query for better responses\"\"\"\n",
        "        if 'total_sales_metrics' in sql_query:\n",
        "            return f\"{self.schema_info.get('total_sales_metrics', {}).get('row_count', 'many')}\"\n",
        "        elif 'ad_sales_metrics' in sql_query:\n",
        "            return f\"{self.schema_info.get('ad_sales_metrics', {}).get('row_count', 'many')}\"\n",
        "        return \"multiple\"\n",
        "\n",
        "    def _generate_insights(self, result, question):\n",
        "        \"\"\"Generate quick insights from the results\"\"\"\n",
        "        if len(result) == 0:\n",
        "            return \"No data found.\"\n",
        "\n",
        "        insights = []\n",
        "\n",
        "        # Numeric column insights\n",
        "        numeric_cols = result.select_dtypes(include=[np.number]).columns\n",
        "        for col in numeric_cols:\n",
        "            if len(result[col]) > 1:\n",
        "                max_val = result[col].max()\n",
        "                min_val = result[col].min()\n",
        "                avg_val = result[col].mean()\n",
        "\n",
        "                if 'roas' in col.lower():\n",
        "                    insights.append(f\"RoAS ranges from {min_val:.2f} to {max_val:.2f}\")\n",
        "                elif 'cpc' in col.lower():\n",
        "                    insights.append(f\"CPC ranges from ${min_val:.2f} to ${max_val:.2f}\")\n",
        "                elif 'sales' in col.lower():\n",
        "                    insights.append(f\"Sales range from ${min_val:,.2f} to ${max_val:,.2f}\")\n",
        "\n",
        "        return \". \".join(insights[:2]) if insights else \"Data retrieved successfully.\"\n",
        "\n",
        "    def chat(self, question):\n",
        "        \"\"\"Main conversational interface\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Understand user intent\n",
        "        intent = self.understand_intent(question)\n",
        "\n",
        "        # Generate SQL with context\n",
        "        sql_query = self.generate_enhanced_sql(question, intent)\n",
        "\n",
        "        # Execute query with retry logic\n",
        "        result = self.execute_query_with_retry(sql_query)\n",
        "\n",
        "        # Format conversational response\n",
        "        formatted_response = self.format_conversational_response(question, result, sql_query, intent)\n",
        "\n",
        "        # Create visualization if appropriate\n",
        "        chart = self._create_smart_visualization(result, question, intent)\n",
        "\n",
        "        # Store in conversation history\n",
        "        conversation_item = {\n",
        "            'timestamp': datetime.now(),\n",
        "            'question': question,\n",
        "            'intent': intent,\n",
        "            'sql_query': sql_query,\n",
        "            'result': formatted_response,\n",
        "            'execution_time': time.time() - start_time,\n",
        "            'data': result if not isinstance(result, str) else None\n",
        "        }\n",
        "\n",
        "        self.conversation_history.append(conversation_item)\n",
        "\n",
        "        # Update context memory\n",
        "        self._update_context_memory(question, intent)\n",
        "\n",
        "        return {\n",
        "            'question': question,\n",
        "            'sql_query': sql_query,\n",
        "            'response': formatted_response,\n",
        "            'chart': chart,\n",
        "            'execution_time': conversation_item['execution_time'],\n",
        "            'intent': intent\n",
        "        }\n",
        "\n",
        "    def _create_smart_visualization(self, result, question, intent):\n",
        "        \"\"\"Create intelligent visualizations based on data and context\"\"\"\n",
        "        if isinstance(result, str) or len(result) == 0:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # Don't create charts for single values\n",
        "            if len(result) == 1 and len(result.columns) == 1:\n",
        "                return None\n",
        "\n",
        "            # Chart for RoAS data\n",
        "            if intent['output_type'] == 'table' and any('roas' in col.lower() for col in result.columns):\n",
        "                if len(result) <= 20:\n",
        "                    roas_col = [col for col in result.columns if 'roas' in col.lower()][0]\n",
        "                    item_col = [col for col in result.columns if 'item' in col.lower()]\n",
        "                    if item_col:\n",
        "                        fig = px.bar(result.head(15),\n",
        "                                   x=item_col[0],\n",
        "                                   y=roas_col,\n",
        "                                   title=\"Return on Ad Spend (RoAS) by Product\",\n",
        "                                   labels={roas_col: \"RoAS\", item_col[0]: \"Product ID\"})\n",
        "                        return fig\n",
        "\n",
        "            # Chart for CPC data\n",
        "            elif intent['output_type'] == 'table' and any('cpc' in col.lower() for col in result.columns):\n",
        "                if len(result) <= 20:\n",
        "                    cpc_col = [col for col in result.columns if 'cpc' in col.lower()][0]\n",
        "                    item_col = [col for col in result.columns if 'item' in col.lower()]\n",
        "                    if item_col:\n",
        "                        fig = px.bar(result.head(15),\n",
        "                                   x=item_col[0],\n",
        "                                   y=cpc_col,\n",
        "                                   title=\"Cost Per Click (CPC) by Product\",\n",
        "                                   labels={cpc_col: \"CPC ($)\", item_col[0]: \"Product ID\"})\n",
        "                        return fig\n",
        "\n",
        "            # Time series charts\n",
        "            elif any('date' in col.lower() for col in result.columns):\n",
        "                date_col = [col for col in result.columns if 'date' in col.lower()][0]\n",
        "                numeric_cols = result.select_dtypes(include=[np.number]).columns\n",
        "                if len(numeric_cols) > 0:\n",
        "                    value_col = numeric_cols[0]\n",
        "                    fig = px.line(result,\n",
        "                                x=date_col,\n",
        "                                y=value_col,\n",
        "                                title=f\"{value_col.title()} Over Time\")\n",
        "                    return fig\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Visualization error: {e}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _update_context_memory(self, question, intent):\n",
        "        \"\"\"Update conversation context for better future responses\"\"\"\n",
        "        # Track frequently asked questions\n",
        "        q_key = question.lower()\n",
        "        self.context_memory['frequently_asked'][q_key] = self.context_memory['frequently_asked'].get(q_key, 0) + 1\n",
        "\n",
        "        # Track user preferences\n",
        "        if intent['output_type'] == 'chart':\n",
        "            self.context_memory['user_preferences']['likes_charts'] = True\n",
        "\n",
        "        # Keep last 10 queries for context\n",
        "        self.context_memory['last_queries'].append(question)\n",
        "        if len(self.context_memory['last_queries']) > 10:\n",
        "            self.context_memory['last_queries'].pop(0)\n",
        "\n",
        "    def get_conversation_summary(self):\n",
        "        \"\"\"Get a summary of the conversation\"\"\"\n",
        "        if not self.conversation_history:\n",
        "            return \"No conversation history yet.\"\n",
        "\n",
        "        summary = f\"**Conversation Summary** ({len(self.conversation_history)} questions asked)\\n\\n\"\n",
        "\n",
        "        for i, item in enumerate(self.conversation_history[-5:], 1):\n",
        "            summary += f\"{i}. Q: {item['question']}\\n\"\n",
        "            summary += f\"   Intent: {item['intent']['intent']}\\n\"\n",
        "            summary += f\"   Time: {item['execution_time']:.2f}s\\n\\n\"\n",
        "\n",
        "        return summary\n",
        "\n",
        "# Initialize the enhanced conversational agent\n",
        "print(\"üöÄ Initializing Conversational AI Agent...\")\n",
        "\n",
        "try:\n",
        "    conv_agent = ConversationalEcommerceAgent()\n",
        "\n",
        "    if conv_agent.schema_info:\n",
        "        print(\"‚úÖ Conversational AI Agent ready!\")\n",
        "        print(f\"üìä Database loaded with {len(conv_agent.schema_info)} tables\")\n",
        "\n",
        "        # Show capabilities\n",
        "        print(\"\\nüéØ ENHANCED CAPABILITIES:\")\n",
        "        print(\"‚úÖ Unlimited questions and follow-ups\")\n",
        "        print(\"‚úÖ Conversation memory and context\")\n",
        "        print(\"‚úÖ Smart intent understanding\")\n",
        "        print(\"‚úÖ Automatic error recovery\")\n",
        "        print(\"‚úÖ Intelligent visualizations\")\n",
        "        print(\"‚úÖ Conversational responses\")\n",
        "\n",
        "        print(\"\\nüí¨ Ready for real-time conversation!\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Failed to load database schema\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing conversational agent: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA0QZD116xvF",
        "outputId": "f3470ed8-da0e-4900-df7c-cdd26dd79821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Initializing Conversational AI Agent...\n",
            "‚úÖ Conversational AI Agent ready!\n",
            "üìä Database loaded with 3 tables\n",
            "\n",
            "üéØ ENHANCED CAPABILITIES:\n",
            "‚úÖ Unlimited questions and follow-ups\n",
            "‚úÖ Conversation memory and context\n",
            "‚úÖ Smart intent understanding\n",
            "‚úÖ Automatic error recovery\n",
            "‚úÖ Intelligent visualizations\n",
            "‚úÖ Conversational responses\n",
            "\n",
            "üí¨ Ready for real-time conversation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Gradio Interface for Real-Time Conversation\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "def chat_with_agent(message, history):\n",
        "    \"\"\"Process user message and return conversational response\"\"\"\n",
        "    if not message.strip():\n",
        "        return history, \"\"\n",
        "\n",
        "    try:\n",
        "        # Get response from conversational agent\n",
        "        response = conv_agent.chat(message)\n",
        "\n",
        "        # Format the response for chat interface\n",
        "        bot_response = f\"**ü§ñ AI Agent Response:**\\n\\n{response['response']}\"\n",
        "\n",
        "        # Add SQL query info (collapsible)\n",
        "        if not response['sql_query'].startswith('Error'):\n",
        "            bot_response += f\"\\n\\n<details><summary>üîç <i>View SQL Query</i></summary>\\n\\n```sql\\n{response['sql_query']}\\n```\\n</details>\"\n",
        "\n",
        "        # Add execution time\n",
        "        bot_response += f\"\\n\\n‚ö° *Processed in {response['execution_time']:.2f} seconds*\"\n",
        "\n",
        "        # Update history\n",
        "        history.append([message, bot_response])\n",
        "\n",
        "        return history, \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_response = f\"I apologize, but I encountered an error: {str(e)}\\n\\nPlease try rephrasing your question or ask something else!\"\n",
        "        history.append([message, error_response])\n",
        "        return history, \"\"\n",
        "\n",
        "def show_chart_for_last_query():\n",
        "    \"\"\"Show chart for the last query if available\"\"\"\n",
        "    if conv_agent.conversation_history:\n",
        "        last_item = conv_agent.conversation_history[-1]\n",
        "        chart = conv_agent._create_smart_visualization(\n",
        "            last_item.get('data'),\n",
        "            last_item['question'],\n",
        "            last_item['intent']\n",
        "        )\n",
        "        return chart\n",
        "    return None\n",
        "\n",
        "def get_conversation_summary():\n",
        "    \"\"\"Get conversation summary\"\"\"\n",
        "    return conv_agent.get_conversation_summary()\n",
        "\n",
        "def clear_conversation():\n",
        "    \"\"\"Clear conversation history\"\"\"\n",
        "    conv_agent.conversation_history = []\n",
        "    return [], \"\"\n",
        "\n",
        "# Create the enhanced Gradio interface\n",
        "with gr.Blocks(\n",
        "    title=\"E-commerce AI Agent - Real-Time Conversation\",\n",
        "    theme=gr.themes.Soft(),\n",
        "    css=\"\"\"\n",
        "    .gradio-container {\n",
        "        max-width: 1200px !important;\n",
        "    }\n",
        "    .chat-message {\n",
        "        border-radius: 10px !important;\n",
        "    }\n",
        "    \"\"\"\n",
        ") as demo:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üõí E-commerce AI Agent - Real-Time Conversation\n",
        "\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            # Main chat interface\n",
        "            chatbot = gr.Chatbot(\n",
        "                height=400,\n",
        "                show_label=False,\n",
        "                container=True,\n",
        "                bubble_full_width=False\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                msg = gr.Textbox(\n",
        "                    placeholder=\"Ask me about your e-commerce data... (e.g., 'What are my top performing products?')\",\n",
        "                    show_label=False,\n",
        "                    scale=4,\n",
        "                    container=False\n",
        "                )\n",
        "                send_btn = gr.Button(\"Send üì§\", scale=1, variant=\"primary\")\n",
        "                clear_btn = gr.Button(\"Clear üóëÔ∏è\", scale=1, variant=\"secondary\")\n",
        "\n",
        "            # Example questions\n",
        "            with gr.Row():\n",
        "                gr.Examples(\n",
        "                    examples=[\n",
        "                        [\"What is my total sales revenue?\"],\n",
        "                        [\"Calculate the RoAS for all products\"],\n",
        "                        [\"Which product has the highest CPC?\"],\n",
        "                        [\"Show me products with RoAS above 5\"],\n",
        "                        [\"What's the average conversion rate?\"],\n",
        "                        [\"Which products are not eligible for advertising?\"],\n",
        "                        [\"Compare ad spend vs organic sales\"],\n",
        "                        [\"Show me the worst performing products\"],\n",
        "                        [\"What's my most profitable product?\"],\n",
        "                        [\"Analyze trends in my sales data\"]\n",
        "                    ],\n",
        "                    inputs=msg,\n",
        "                    label=\"üí° Try these example questions:\"\n",
        "                )\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            # Visualization panel\n",
        "            gr.Markdown(\"### üìä Visualizations\")\n",
        "            chart_display = gr.Plot(label=\"Chart\")\n",
        "            chart_btn = gr.Button(\"Show Chart for Last Query üìà\", variant=\"secondary\")\n",
        "\n",
        "            # Conversation summary\n",
        "            gr.Markdown(\"### üìù Conversation Summary\")\n",
        "            summary_display = gr.Textbox(\n",
        "                label=\"Summary\",\n",
        "                lines=6,\n",
        "                interactive=False\n",
        "            )\n",
        "            summary_btn = gr.Button(\"Update Summary üìã\", variant=\"secondary\")\n",
        "\n",
        "    # Event handlers\n",
        "    def respond_and_update(message, history):\n",
        "        \"\"\"Handle message and update all components\"\"\"\n",
        "        new_history, cleared_msg = chat_with_agent(message, history)\n",
        "        chart = show_chart_for_last_query()\n",
        "        summary = get_conversation_summary()\n",
        "        return new_history, cleared_msg, chart, summary\n",
        "\n",
        "    # Button events\n",
        "    send_btn.click(\n",
        "        respond_and_update,\n",
        "        inputs=[msg, chatbot],\n",
        "        outputs=[chatbot, msg, chart_display, summary_display]\n",
        "    )\n",
        "\n",
        "    msg.submit(\n",
        "        respond_and_update,\n",
        "        inputs=[msg, chatbot],\n",
        "        outputs=[chatbot, msg, chart_display, summary_display]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        clear_conversation,\n",
        "        outputs=[chatbot, summary_display]\n",
        "    )\n",
        "\n",
        "    chart_btn.click(\n",
        "        show_chart_for_last_query,\n",
        "        outputs=chart_display\n",
        "    )\n",
        "\n",
        "    summary_btn.click(\n",
        "        get_conversation_summary,\n",
        "        outputs=summary_display\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "\n",
        "    \"\"\")\n",
        "\n",
        "# Launch the enhanced interface\n",
        "print(\"üöÄ Launching Real-Time Conversational Interface...\")\n",
        "\n",
        "demo.launch(\n",
        "    share=True,\n",
        "    debug=True,\n",
        "    server_name=\"0.0.0.0\",\n",
        "    server_port=7860,\n",
        "    show_error=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Real-time conversational interface is now running!\")\n",
        "print(\"üí¨ You can now have unlimited conversations with your AI agent!\")"
      ],
      "metadata": {
        "id": "_f4RIuNe7nxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Test required questions\n",
        "required_questions = [\n",
        "    \"What is my total sales?\",\n",
        "    \"Calculate the RoAS (Return on Ad Spend)\",\n",
        "    \"Which product had the highest CPC (Cost Per Click)?\"\n",
        "]\n",
        "\n",
        "print(\"üß™ Testing Required Questions:\\n\" + \"=\"*50)\n",
        "\n",
        "for i, question in enumerate(required_questions, 1):\n",
        "    print(f\"\\n{i}. Question: {question}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    result = agent.process_question(question)\n",
        "\n",
        "    print(f\"SQL Query: {result['sql_query']}\")\n",
        "    print(f\"Answer: {result['result']}\")\n",
        "\n",
        "    if result.get('chart'):\n",
        "        result['chart'].show()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)"
      ],
      "metadata": {
        "id": "0QkTQUcoyFKJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "5b46c06a-c7f1-444d-c3f2-f522c0402508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Testing Required Questions:\n",
            "==================================================\n",
            "\n",
            "1. Question: What is my total sales?\n",
            "----------------------------------------\n",
            "SQL Query: SELECT SUM(ad_sales) + SUM(total_sales) AS total_sales FROM ad_sales_metrics AS asm JOIN total_sales_metrics AS tsm ON asm.item_id = tsm.item_id LIMIT 100;\n",
            "Answer: Answer: 18,974,321.79\n",
            "\n",
            "==================================================\n",
            "\n",
            "2. Question: Calculate the RoAS (Return on Ad Spend)\n",
            "----------------------------------------\n",
            "SQL Query: SELECT\n",
            "  (SUM(ad_sales) + SUM(total_sales)) / SUM(ad_spend) AS RoAS\n",
            "FROM ad_sales_metrics\n",
            "JOIN total_sales_metrics\n",
            "  ON ad_sales_metrics.item_id = total_sales_metrics.item_id AND ad_sales_metrics.date = total_sales_metrics.date\n",
            "LIMIT 100;\n",
            "Answer: Answer: 27.15\n",
            "\n",
            "==================================================\n",
            "\n",
            "3. Question: Which product had the highest CPC (Cost Per Click)?\n",
            "----------------------------------------\n",
            "SQL Query: SELECT item_id\n",
            "FROM ad_sales_metrics\n",
            "WHERE clicks > 0\n",
            "ORDER BY ad_spend/clicks DESC\n",
            "LIMIT 1;\n",
            "Answer: Answer: 22\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Export functionality\n",
        "def export_project():\n",
        "    \"\"\"Export the complete project\"\"\"\n",
        "\n",
        "    # Create a summary report\n",
        "    report = {\n",
        "        'project_name': 'E-commerce AI Agent',\n",
        "        'created_at': datetime.now().isoformat(),\n",
        "        'database_schema': agent.schema_info,\n",
        "        'test_results': []\n",
        "    }\n",
        "\n",
        "    # Test all required questions\n",
        "    for question in required_questions:\n",
        "        result = agent.process_question(question)\n",
        "        report['test_results'].append({\n",
        "            'question': question,\n",
        "            'sql_query': result['sql_query'],\n",
        "            'answer': result['result']\n",
        "        })\n",
        "\n",
        "    # Save report\n",
        "    with open('project_report.json', 'w') as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "\n",
        "    # Create Python script version\n",
        "    script_content = f'''\n",
        "# E-commerce AI Agent - Standalone Version\n",
        "# Generated from Google Colab\n",
        "\n",
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import gradio as gr\n",
        "\n",
        "# Configure your API key\n",
        "genai.configure(api_key=\"YOUR_API_KEY_HERE\")\n",
        "\n",
        "# [Insert the complete EcommerceAIAgent class here]\n",
        "class EcommerceAIAgent:\n",
        "    # ... (copy the class from Cell 5)\n",
        "\n",
        "# Usage example:\n",
        "if __name__ == \"__main__\":\n",
        "    agent = EcommerceAIAgent()\n",
        "\n",
        "    # Test questions\n",
        "    questions = {required_questions}\n",
        "\n",
        "    for question in questions:\n",
        "        result = agent.process_question(question)\n",
        "        print(f\"Q: {{result['question']}}\")\n",
        "        print(f\"A: {{result['result']}}\\\\n\")\n",
        "'''\n",
        "\n",
        "    with open('ecommerce_ai_agent.py', 'w') as f:\n",
        "        f.write(script_content)\n",
        "\n",
        "    # Download files\n",
        "    files.download('project_report.json')\n",
        "    files.download('ecommerce_ai_agent.py')\n",
        "    files.download('ecommerce_data.db')\n",
        "\n",
        "    print(\"‚úÖ Project exported successfully!\")\n",
        "    print(\"üìÅ Files downloaded: project_report.json, ecommerce_ai_agent.py, ecommerce_data.db\")\n",
        "\n",
        "# Call export function\n",
        "export_project()"
      ],
      "metadata": {
        "id": "RLVwR0KQyIso",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "41b838d5-23fb-4016-ebca-389ec6b79d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a99fab84-3dac-4fb3-84b4-fec1979f3661\", \"project_report.json\", 2552)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c69b65b9-298f-4ede-9fe0-86ec6a548b0e\", \"ecommerce_ai_agent.py\", 759)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_39ef9b12-ad96-4796-996f-bb12bf9b274b\", \"ecommerce_data.db\", 823296)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Project exported successfully!\n",
            "üìÅ Files downloaded: project_report.json, ecommerce_ai_agent.py, ecommerce_data.db\n"
          ]
        }
      ]
    }
  ]
}